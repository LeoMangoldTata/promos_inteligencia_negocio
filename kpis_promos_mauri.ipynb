{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importamos librerias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tKk581G_hMT0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snowflake.connector\n",
    "import json\n",
    "import os\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChvQTwl1D-Ls",
    "outputId": "351b443f-8ebf-4a34-f7ba-93fb012f5082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "\n",
    "        f = open('credentials.json')\n",
    "        data_pass = json.load(f)\n",
    "\n",
    "        pass_ = input(\"INGRESAR PASSCODE:\")\n",
    "\n",
    "        ctx = snowflake.connector.connect(\n",
    "            user = data_pass['snow']['USER'],\n",
    "            password = data_pass['snow']['PASS'],\n",
    "            account = data_pass['snow']['ACCOUNT'],\n",
    "            passcode = pass_,\n",
    "            database = 'SANDBOX_PLUS',\n",
    "            schema = 'DWH'\n",
    "        )\n",
    "\n",
    "        cursor = ctx.cursor()\n",
    "\n",
    "        print('Connected')\n",
    "\n",
    "        break\n",
    "\n",
    "    except:\n",
    "        print('Incorrect Password - provide again')\n",
    "\n",
    "    print('Correct Password - connected to SNOWFLAKE')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Periodos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "periodo = input(\"Periodo - ejemplo 2023-01:\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OTROS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [TIPO_OFERTA_ID, TIPO_OFERTA_DESC, EVENTO_DESC, INICIO, FIN, CLASE, CLASS_NAME, SUBCLASE, SUB_NAME, ORIN, ARTC_ARTC_DESC, GEOG_LOCL_ID, GEOG_LOCL_COD, GEOG_LOCL_DESC]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIPO_OFERTA_ID</th>\n      <th>TIPO_OFERTA_DESC</th>\n      <th>EVENTO_DESC</th>\n      <th>INICIO</th>\n      <th>FIN</th>\n      <th>CLASE</th>\n      <th>CLASS_NAME</th>\n      <th>SUBCLASE</th>\n      <th>SUB_NAME</th>\n      <th>ORIN</th>\n      <th>ARTC_ARTC_DESC</th>\n      <th>GEOG_LOCL_ID</th>\n      <th>GEOG_LOCL_COD</th>\n      <th>GEOG_LOCL_DESC</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    LPTO.*,\n",
    "    LPE.EVENTO_DESC,\n",
    "    FP.PROM_FECHA_INICIO AS INICIO,\n",
    "    FP.PROM_FECHA_FIN AS FIN,\n",
    "    CLA.CLASE,\n",
    "    CLA.CLASS_NAME,\n",
    "    SUB.SUBCLASE,\n",
    "    SUB.SUB_NAME,\n",
    "    LAA.ORIN,\n",
    "    LAA.ARTC_ARTC_DESC,\n",
    "    FP.GEOG_LOCL_ID,\n",
    "    LGL.GEOG_LOCL_COD,\n",
    "    LGL.GEOG_LOCL_DESC\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_PROMOS AS FP\n",
    "    INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "    INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "    INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "    INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "WHERE\n",
    "    LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "    AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "df = cursor.fetch_pandas_all()\n",
    "df.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Articulos Publicados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 1 - Articulos Publicados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [TIPO_OFERTA_ID, TIPO_OFERTA_DESC, EVENTO_DESC, INICIO, FIN, GEOG_LOCL_COD, GEOG_LOCL_DESC, CLASE, CLASS_NAME, SUBCLASE, SUB_NAME, NUMERO_ARTICULOS]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIPO_OFERTA_ID</th>\n      <th>TIPO_OFERTA_DESC</th>\n      <th>EVENTO_DESC</th>\n      <th>INICIO</th>\n      <th>FIN</th>\n      <th>GEOG_LOCL_COD</th>\n      <th>GEOG_LOCL_DESC</th>\n      <th>CLASE</th>\n      <th>CLASS_NAME</th>\n      <th>SUBCLASE</th>\n      <th>SUB_NAME</th>\n      <th>NUMERO_ARTICULOS</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_1 = df.groupby(['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'EVENTO_DESC', 'INICIO', 'FIN', 'GEOG_LOCL_COD', 'GEOG_LOCL_DESC','CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['ORIN'].nunique().reset_index()\n",
    "e_1.rename({'ORIN':'NUMERO_ARTICULOS'}, axis = 1, inplace = True)\n",
    "e_1.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ventas, GB1 & Numero de Subclases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Queries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [TIPO_OFERTA_ID, TIPO_OFERTA_DESC, TIEM_DIA_ID, CLASE, CLASS_NAME, SUBCLASE, SUB_NAME, ORIN, GEOG_LOCL_COD, INICIO, FIN, VENTA_SIN_IVA, COSTO, GB1]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIPO_OFERTA_ID</th>\n      <th>TIPO_OFERTA_DESC</th>\n      <th>TIEM_DIA_ID</th>\n      <th>CLASE</th>\n      <th>CLASS_NAME</th>\n      <th>SUBCLASE</th>\n      <th>SUB_NAME</th>\n      <th>ORIN</th>\n      <th>GEOG_LOCL_COD</th>\n      <th>INICIO</th>\n      <th>FIN</th>\n      <th>VENTA_SIN_IVA</th>\n      <th>COSTO</th>\n      <th>GB1</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "WITH PROMOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        LPE.EVENTO_DESC,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        CLA.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_DESC\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    PROMOS.TIPO_OFERTA_ID,\n",
    "    PROMOS.TIPO_OFERTA_DESC,\n",
    "    FV.TIEM_DIA_ID,\n",
    "    IM.CLASE,\n",
    "    CLA.CLASS_NAME,\n",
    "    IM.SUBCLASE,\n",
    "    SUB.SUB_NAME,\n",
    "    LAA.ORIN,\n",
    "    LGL.GEOG_LOCL_COD,\n",
    "    PROMOS.INICIO,\n",
    "    PROMOS.FIN,\n",
    "    FV.VNTA_IMPORTE_SIN_IVA AS VENTA_SIN_IVA,\n",
    "    FV.VNTA_UNIDADES * FV.VNTA_COSTO_PROM_POND AS COSTO,\n",
    "    VENTA_SIN_IVA - COSTO AS GB1\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_VENTAS AS FV\n",
    "    INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON FV.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FV .ARTC_ARTC_ID\n",
    "    INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "    INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "    INNER JOIN PROMOS ON PROMOS.ORIN = LAA.ORIN AND PROMOS.GEOG_LOCL_COD = LGL.GEOG_LOCL_COD AND FV.TIEM_DIA_ID BETWEEN PROMOS.INICIO AND PROMOS.FIN\n",
    "WHERE\n",
    "    TO_VARCHAR(FV.TIEM_DIA_ID, 'YYYY-MM') = '{periodo_query}'\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "arts_1 = cursor.fetch_pandas_all()\n",
    "print(arts_1.shape[0])\n",
    "arts_1.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [TIEM_DIA_ID, CLASE, CLASS_NAME, SUBCLASE, SUB_NAME, ORIN, GEOG_LOCL_COD, VENTA_SIN_IVA_TOTAL, COSTO, GB1_TOTAL]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIEM_DIA_ID</th>\n      <th>CLASE</th>\n      <th>CLASS_NAME</th>\n      <th>SUBCLASE</th>\n      <th>SUB_NAME</th>\n      <th>ORIN</th>\n      <th>GEOG_LOCL_COD</th>\n      <th>VENTA_SIN_IVA_TOTAL</th>\n      <th>COSTO</th>\n      <th>GB1_TOTAL</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "WITH PROMOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        LPE.EVENTO_DESC,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        CLA.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_DESC\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    FV.TIEM_DIA_ID,\n",
    "    IM.CLASE,\n",
    "    CLA.CLASS_NAME,\n",
    "    IM.SUBCLASE,\n",
    "    SUB.SUB_NAME,\n",
    "    LAA.ORIN,\n",
    "    LGL.GEOG_LOCL_COD,\n",
    "    FV.VNTA_IMPORTE_SIN_IVA AS VENTA_SIN_IVA_TOTAL,\n",
    "    FV.VNTA_UNIDADES * FV.VNTA_COSTO_PROM_POND AS COSTO,\n",
    "    VENTA_SIN_IVA_TOTAL - COSTO AS GB1_TOTAL\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_VENTAS AS FV\n",
    "    INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON FV.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FV .ARTC_ARTC_ID\n",
    "    INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "    INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "    INNER JOIN PROMOS ON PROMOS.SUBCLASE = IM.SUBCLASE AND PROMOS.GEOG_LOCL_COD = LGL.GEOG_LOCL_COD AND FV.TIEM_DIA_ID BETWEEN PROMOS.INICIO AND PROMOS.FIN\n",
    "WHERE\n",
    "    TO_VARCHAR(FV.TIEM_DIA_ID, 'YYYY-MM') = '{periodo_query}'\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "subs_1 = cursor.fetch_pandas_all()\n",
    "print(subs_1.shape[0])\n",
    "subs_1.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonardo.mangold\\AppData\\Local\\Temp\\ipykernel_13980\\4176392989.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  subs_2 = subs_1.groupby(['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['VENTA_SIN_IVA_TOTAL', 'GB1_TOTAL'].sum().reset_index()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'VENTA_SIN_IVA_TOTAL'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Desktop\\Tareas\\Analisis\\!Python\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3361\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3362\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\Desktop\\Tareas\\Analisis\\!Python\\env\\lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Desktop\\Tareas\\Analisis\\!Python\\env\\lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'VENTA_SIN_IVA_TOTAL'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m subs_2 \u001B[38;5;241m=\u001B[39m subs_1\u001B[38;5;241m.\u001B[39mgroupby([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCLASE\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCLASS_NAME\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSUBCLASE\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSUB_NAME\u001B[39m\u001B[38;5;124m'\u001B[39m])[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVENTA_SIN_IVA_TOTAL\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGB1_TOTAL\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVENTA_SIN_IVA_TOTAL\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGB1_TOTAL\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m----> 4\u001B[0m     subs_2[i] \u001B[38;5;241m=\u001B[39m \u001B[43msubs_2\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m      6\u001B[0m subs_2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mREF_2\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVenta Total\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      8\u001B[0m subs_2 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([subs_2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mREF_2\u001B[39m\u001B[38;5;124m'\u001B[39m], subs_2\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mREF_2\u001B[39m\u001B[38;5;124m'\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\Tareas\\Analisis\\!Python\\env\\lib\\site-packages\\pandas\\core\\frame.py:3458\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3457\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3458\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3459\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3460\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\Desktop\\Tareas\\Analisis\\!Python\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3362\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3363\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3365\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_scalar(key) \u001B[38;5;129;01mand\u001B[39;00m isna(key) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhasnans:\n\u001B[0;32m   3366\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'VENTA_SIN_IVA_TOTAL'"
     ]
    }
   ],
   "source": [
    "subs_2 = subs_1.groupby(['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['VENTA_SIN_IVA_TOTAL', 'GB1_TOTAL'].sum().reset_index()\n",
    "\n",
    "for i in ['VENTA_SIN_IVA_TOTAL', 'GB1_TOTAL']:\n",
    "    subs_2[i] = subs_2[i].astype(int)\n",
    "\n",
    "subs_2['REF_2'] = 'Venta Total'\n",
    "\n",
    "subs_2 = pd.concat([subs_2['REF_2'], subs_2.drop('REF_2', axis=1)], axis=1)\n",
    "subs_2.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 2 - Venta y GB1 por Promo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arts_2 = arts_1.groupby(['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['VENTA_SIN_IVA', 'GB1'].sum().reset_index()\n",
    "for i in ['VENTA_SIN_IVA', 'GB1']:\n",
    "    arts_2[i] = arts_2[i].astype(int)\n",
    "\n",
    "arts_2['GB1_%'] = round(arts_2['GB1'] / arts_2['VENTA_SIN_IVA'] * 100, 1)\n",
    "arts_2['REF'] = 'Venta Promo'\n",
    "\n",
    "arts_2 = pd.concat([arts_2['REF'], arts_2.drop('REF', axis=1)], axis=1)\n",
    "\n",
    "arts_2.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 3 - Numero de Subclases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arts_2.head(2)\n",
    "arts_4 = arts_2.groupby(['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC'])['SUBCLASE'].nunique().reset_index()\n",
    "arts_4.rename({'SUBCLASE':'NUMERO_SUBCLASES'}, axis = 1, inplace = True)\n",
    "arts_4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arts_1[['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'INICIO', 'FIN', 'GEOG_LOCL_COD']].drop_duplicates()\n",
    "unicos = arts_1[['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'INICIO', 'FIN']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'arts_1' is your original dataframe\n",
    "# Extracting required columns and dropping duplicates for both dataframes\n",
    "A = arts_1[['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'INICIO', 'FIN', 'GEOG_LOCL_COD']].drop_duplicates()\n",
    "unicos = arts_1[['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'INICIO', 'FIN']].drop_duplicates()\n",
    "\n",
    "# Merge dataframes on common columns\n",
    "merged_df = pd.merge(unicos, A, on=['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'INICIO', 'FIN'], how='left')\n",
    "\n",
    "# Group by the specified columns and aggregate 'GEOG_LOCL_COD' values into parentheses\n",
    "grouped_df = merged_df.groupby(['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'INICIO', 'FIN'])['GEOG_LOCL_COD'].agg(\n",
    "    lambda x: tuple(x) if len(x) > 1 else (x.iloc[0]) if not x.empty else None\n",
    ").reset_index()\n",
    "\n",
    "# Rename the aggregated column\n",
    "grouped_df.rename(columns={'GEOG_LOCL_COD': 'LOCALES'}, inplace=True)\n",
    "\n",
    "# Merge the grouped dataframe back to the original 'unicos' dataframe\n",
    "unicos = pd.merge(unicos, grouped_df, on=['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'INICIO', 'FIN'], how='left')\n",
    "\n",
    "unicos['LOCALES'] = list(map(lambda x: str(x).replace('(', '').replace(')', ''), unicos['LOCALES']))\n",
    "unicos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arts_5 = pd.DataFrame()\n",
    "\n",
    "query = '''\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    LGL.GEOG_LOCL_COD,\n",
    "    IM.SUBCLASE\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_VENTAS AS FV\n",
    "    INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FV.GEOG_LOCL_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON FV.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID\n",
    "    INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "WHERE\n",
    "    FV.TIEM_DIA_ID BETWEEN '{inicio_snow}' AND '{fin_snow}'\n",
    "    AND LGL.GEOG_LOCL_COD IN ({locales_snow})\n",
    "'''\n",
    "\n",
    "for i in range(unicos.shape[0]):\n",
    "    tipo_oferta_id = unicos.loc[i]['TIPO_OFERTA_ID']\n",
    "    tipo_oferta_desc = unicos.loc[i]['TIPO_OFERTA_DESC']\n",
    "    inicio = unicos.loc[i]['INICIO']\n",
    "    fin = unicos.loc[i]['FIN']\n",
    "    locales = unicos.loc[i]['LOCALES']\n",
    "\n",
    "    cursor.execute(query.format(inicio_snow = inicio, fin_snow = fin, locales_snow = locales))\n",
    "    df_aux = cursor.fetch_pandas_all()\n",
    "    df_aux['TIPO_OFERTA_ID'] = tipo_oferta_id\n",
    "    df_aux['TIPO_OFERTA_DESC'] = tipo_oferta_desc\n",
    "    arts_5 = pd.concat([arts_5, df_aux])\n",
    "\n",
    "arts_6 = arts_5.groupby(['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC'])['SUBCLASE'].nunique().reset_index()\n",
    "arts_6.rename({'SUBCLASE':'NUMERO_SUBCLASES_TOTALES'}, axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 3 - Numero de Subclases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_6 = arts_4.merge(arts_6, on = ['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC'], how = 'inner')\n",
    "e_6['RATIO'] = round(e_6['NUMERO_SUBCLASES'] / e_6['NUMERO_SUBCLASES_TOTALES'] * 100, 1)\n",
    "e_6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 4 - Venta y GB1 por Subclase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hay subclases que estan presentes en mas de una promo\n",
    "arts_2[arts_2['SUB_NAME'].duplicated()]\n",
    "arts_2[arts_2['SUBCLASE'] == 100020003]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Para comparar con las ventas de la subclase o clase, tengo que agrupar y perder el tipo de oferta\n",
    "arts_3 = arts_2.groupby(['REF', 'CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['VENTA_SIN_IVA', 'GB1'].sum().reset_index()\n",
    "arts_3.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_2 = arts_3.merge(subs_2, on = ['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'], how = 'inner')\n",
    "e_2['RATIO_VENTAS'] = round((e_2['VENTA_SIN_IVA'] / e_2['VENTA_SIN_IVA_TOTAL']) * 100, 1)\n",
    "e_2['RATIO_GB1'] = round((e_2['GB1'] / e_2['GB1_TOTAL']) * 100, 1)\n",
    "e_2.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 5 - Venta y GB1 Promo Agrupado"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_3 = pd.DataFrame(e_2.sum(axis=0)).T\n",
    "e_3['REF'] = 'Venta Promo'\n",
    "e_3['VENTA_SIN_IVA_MILLONES'] = int(round(e_3['VENTA_SIN_IVA'].astype(int) / 1000000, 0))\n",
    "e_3['GB1_MILLONES'] = int(round(e_3['GB1'].astype(int) / 1000000, 0))\n",
    "e_3.drop(['REF_2'], axis = 1, inplace = True)\n",
    "e_3['REF_2'] = 'Venta Total'\n",
    "e_3['VENTA_SIN_IVA_TOTAL_MILLONES'] = int(round(e_3['VENTA_SIN_IVA_TOTAL'].astype(int) / 1000000, 0))\n",
    "e_3['GB1_TOTAL_MILLONES'] = int(round(e_3['GB1_TOTAL'].astype(int) / 1000000, 0))\n",
    "e_3.drop(['CLASE', 'SUBCLASE', 'GB1', 'VENTA_SIN_IVA', 'VENTA_SIN_IVA_TOTAL', 'GB1_TOTAL', 'RATIO_VENTAS', 'RATIO_GB1', 'CLASS_NAME', 'SUB_NAME'], axis = 1, inplace = True)\n",
    "e_3['RATIO_VENTAS'] = round((e_3['VENTA_SIN_IVA_MILLONES'] / e_3['VENTA_SIN_IVA_TOTAL_MILLONES']) * 100, 1)\n",
    "e_3['RATIO_GB1'] = round((e_3['GB1_MILLONES'] / e_3['GB1_TOTAL_MILLONES']) * 100, 1)\n",
    "e_3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cantidad de Articulos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Queries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH PROMOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        LPE.EVENTO_DESC,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        CLA.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_DESC\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    PROMOS.TIPO_OFERTA_ID,\n",
    "    PROMOS.TIPO_OFERTA_DESC,\n",
    "    FV.TIEM_DIA_ID,\n",
    "    IM.CLASE,\n",
    "    CLA.CLASS_NAME,\n",
    "    IM.SUBCLASE,\n",
    "    SUB.SUB_NAME,\n",
    "    LAA.ORIN,\n",
    "    LGL.GEOG_LOCL_COD,\n",
    "    FV.VNTA_UNIDADES AS UNIDADES_PROMO\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_VENTAS AS FV\n",
    "    INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON FV.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FV .ARTC_ARTC_ID\n",
    "    INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "    INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "    INNER JOIN PROMOS ON PROMOS.ORIN = LAA.ORIN AND PROMOS.GEOG_LOCL_COD = LGL.GEOG_LOCL_COD AND FV.TIEM_DIA_ID BETWEEN PROMOS.INICIO AND PROMOS.FIN\n",
    "WHERE\n",
    "    TO_VARCHAR(FV.TIEM_DIA_ID, 'YYYY-MM') = '{periodo_query}'\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "cant_1 = cursor.fetch_pandas_all()\n",
    "cant_1['REF'] = 'Venta Promo'\n",
    "print(cant_1.shape[0])\n",
    "cant_1.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Para comparar con las ventas de la subclase o clase, tengo que agrupar y perder el tipo de oferta\n",
    "cant_2 = cant_1.groupby(['REF', 'CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['UNIDADES_PROMO'].sum().reset_index()\n",
    "cant_2.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH PROMOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        LPE.EVENTO_DESC,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        CLA.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_DESC\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    FV.TIEM_DIA_ID,\n",
    "    IM.CLASE,\n",
    "    CLA.CLASS_NAME,\n",
    "    IM.SUBCLASE,\n",
    "    SUB.SUB_NAME,\n",
    "    LAA.ORIN,\n",
    "    LGL.GEOG_LOCL_COD,\n",
    "    FV.VNTA_UNIDADES AS UNIDADES_TOTALES\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_VENTAS AS FV\n",
    "    INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON FV.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FV .ARTC_ARTC_ID\n",
    "    INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "    INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "    INNER JOIN PROMOS ON PROMOS.SUBCLASE = IM.SUBCLASE AND PROMOS.GEOG_LOCL_COD = LGL.GEOG_LOCL_COD AND FV.TIEM_DIA_ID BETWEEN PROMOS.INICIO AND PROMOS.FIN\n",
    "WHERE\n",
    "    TO_VARCHAR(FV.TIEM_DIA_ID, 'YYYY-MM') = '{periodo_query}'\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "sub_cant_1 = cursor.fetch_pandas_all()\n",
    "sub_cant_1['REF_2'] = 'Venta Total'\n",
    "print(sub_cant_1.shape[0])\n",
    "sub_cant_1.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_cant_2 = sub_cant_1.groupby(['REF_2','CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['UNIDADES_TOTALES'].sum().reset_index()\n",
    "sub_cant_2.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 6 - Num Articulos por Subclase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_4 = cant_2.merge(sub_cant_2, on = ['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'], how = 'inner')\n",
    "\n",
    "e_4['RATIO_UNIDADES'] = round(e_4['UNIDADES_PROMO'] / e_4['UNIDADES_TOTALES'] * 100, 1)\n",
    "for i in ['UNIDADES_PROMO', 'UNIDADES_TOTALES']:\n",
    "    e_4[i] = e_4[i].astype(int)\n",
    "\n",
    "e_4.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aceleracion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH DATOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "        FP.EVENTO_ID,\n",
    "        LPE.EVENTO_DESC,\n",
    "        LPTO.TIPO_OFERTA_DESC,\n",
    "        FP.PROM_FECHA_INICIO,\n",
    "        FP.PROM_FECHA_FIN,\n",
    "        DATEDIFF('DAYS', FP.PROM_FECHA_INICIO, FP.PROM_FECHA_FIN) AS DURACION_DIAS,\n",
    "        FP.ARTC_ARTC_ID,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        FP.ARTC_ARTC_ID || FP.GEOG_LOCL_ID AS CLAVE\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        LEFT JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        LEFT JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "    WHERE\n",
    "        LGL.GEOG_UNNG_ID = 2\n",
    "        AND LGL.GEOG_LOCL_COD <> 198\n",
    "    ),\n",
    "\n",
    "BASAL AS\n",
    "    (\n",
    "    SELECT\n",
    "        SPLIT_PART(TIEM_DIA_ID, ' ', 1) AS TIEM_DIA_ID,\n",
    "        GEOG_LOCL_ID,\n",
    "        ARTC_ARTC_ID,\n",
    "        SUM(VENTA_BASAL) AS VENTA_BASAL\n",
    "    FROM\n",
    "        (\n",
    "            SELECT\n",
    "                FVB.TIEM_DIA_ID,\n",
    "                FVB.GEOG_LOCL_ID,\n",
    "                FVB.ARTC_ARTC_ID,\n",
    "                FVB.VENTA_BASAL\n",
    "            FROM\n",
    "                BIZMETRIKS.DWH.FT_VENTA_BASAL AS FVB\n",
    "                INNER JOIN DATOS AS D ON FVB.GEOG_LOCL_ID = D.GEOG_LOCL_ID AND FVB.ARTC_ARTC_ID = D.ARTC_ARTC_ID AND FVB.TIEM_DIA_ID BETWEEN D.PROM_FECHA_INICIO AND D.PROM_FECHA_FIN\n",
    "            WHERE\n",
    "                FVB.TIEM_DIA_ID > DATEADD(YEAR, -1, CURRENT_DATE())\n",
    "            )\n",
    "        GROUP BY\n",
    "            ALL\n",
    "    ),\n",
    "\n",
    "PROMOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        LPE.EVENTO_DESC,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        CLA.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_DESC\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "    ),\n",
    "\n",
    "PROMOS_2 AS\n",
    "    (\n",
    "    SELECT\n",
    "        FV.TIEM_DIA_ID,\n",
    "        IM.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        IM.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ARTC_ARTC_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_ID,\n",
    "        SUM(FV.VNTA_UNIDADES) AS VNTA_UNIDADES\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_VENTAS AS FV\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON FV.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FV .ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN PROMOS ON PROMOS.ORIN = LAA.ORIN AND PROMOS.GEOG_LOCL_COD = LGL.GEOG_LOCL_COD AND FV.TIEM_DIA_ID BETWEEN PROMOS.INICIO AND PROMOS.FIN\n",
    "    WHERE\n",
    "        TO_VARCHAR(FV.TIEM_DIA_ID, 'YYYY-MM') = '{periodo_query}'\n",
    "    GROUP BY\n",
    "        ALL\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    PROMOS_2.*,\n",
    "    BASAL.VENTA_BASAL\n",
    "FROM\n",
    "    PROMOS_2\n",
    "    LEFT JOIN BASAL ON BASAL.TIEM_DIA_ID = PROMOS_2.TIEM_DIA_ID AND BASAL.GEOG_LOCL_ID = PROMOS_2.GEOG_LOCL_ID AND BASAL.ARTC_ARTC_ID = PROMOS_2.ARTC_ARTC_ID\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "ace_perdida = cursor.fetch_pandas_all()\n",
    "ace_perdida.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Filas con Basal missing: {ace_perdida[ace_perdida['VENTA_BASAL'].isna()].shape[0]}\")\n",
    "print(f\"missing para {periodo}: {int(round(ace_perdida[ace_perdida['VENTA_BASAL'].isna()].shape[0] / ace_perdida.shape[0] * 100, 0))}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH DATOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "        FP.EVENTO_ID,\n",
    "        LPE.EVENTO_DESC,\n",
    "        LPTO.TIPO_OFERTA_DESC,\n",
    "        FP.PROM_FECHA_INICIO,\n",
    "        FP.PROM_FECHA_FIN,\n",
    "        DATEDIFF('DAYS', FP.PROM_FECHA_INICIO, FP.PROM_FECHA_FIN) AS DURACION_DIAS,\n",
    "        FP.ARTC_ARTC_ID,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        FP.ARTC_ARTC_ID || FP.GEOG_LOCL_ID AS CLAVE\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        LEFT JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        LEFT JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "    WHERE\n",
    "        LGL.GEOG_UNNG_ID = 2\n",
    "        AND LGL.GEOG_LOCL_COD <> 198\n",
    "    ),\n",
    "\n",
    "BASAL AS\n",
    "    (\n",
    "    SELECT\n",
    "        SPLIT_PART(TIEM_DIA_ID, ' ', 1) AS TIEM_DIA_ID,\n",
    "        GEOG_LOCL_ID,\n",
    "        ARTC_ARTC_ID,\n",
    "        SUM(VENTA_BASAL) AS VENTA_BASAL\n",
    "    FROM\n",
    "        (\n",
    "            SELECT\n",
    "                FVB.TIEM_DIA_ID,\n",
    "                FVB.GEOG_LOCL_ID,\n",
    "                FVB.ARTC_ARTC_ID,\n",
    "                FVB.VENTA_BASAL\n",
    "            FROM\n",
    "                BIZMETRIKS.DWH.FT_VENTA_BASAL AS FVB\n",
    "                INNER JOIN DATOS AS D ON FVB.GEOG_LOCL_ID = D.GEOG_LOCL_ID AND FVB.ARTC_ARTC_ID = D.ARTC_ARTC_ID AND FVB.TIEM_DIA_ID BETWEEN D.PROM_FECHA_INICIO AND D.PROM_FECHA_FIN\n",
    "            WHERE\n",
    "                FVB.TIEM_DIA_ID > DATEADD(YEAR, -1, CURRENT_DATE())\n",
    "            )\n",
    "        GROUP BY\n",
    "            ALL\n",
    "    ),\n",
    "\n",
    "PROMOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        LPE.EVENTO_DESC,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        CLA.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_COD,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_DESC\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "    ),\n",
    "\n",
    "PROMOS_2 AS\n",
    "    (\n",
    "    SELECT\n",
    "        FV.TIEM_DIA_ID,\n",
    "        IM.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        IM.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ARTC_ARTC_ID,\n",
    "        LAA.ARTC_ARTC_COD,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_ID,\n",
    "        SUM(FV.VNTA_UNIDADES) AS VNTA_UNIDADES\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_VENTAS AS FV\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON FV.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FV .ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN PROMOS ON PROMOS.ORIN = LAA.ORIN AND PROMOS.GEOG_LOCL_COD = LGL.GEOG_LOCL_COD AND FV.TIEM_DIA_ID BETWEEN PROMOS.INICIO AND PROMOS.FIN\n",
    "    WHERE\n",
    "        TO_VARCHAR(FV.TIEM_DIA_ID, 'YYYY-MM') = '{periodo_query}'\n",
    "    GROUP BY\n",
    "        ALL\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    PROMOS_2.*,\n",
    "    BASAL.VENTA_BASAL\n",
    "FROM\n",
    "    PROMOS_2\n",
    "    INNER JOIN BASAL ON BASAL.TIEM_DIA_ID = PROMOS_2.TIEM_DIA_ID AND BASAL.GEOG_LOCL_ID = PROMOS_2.GEOG_LOCL_ID AND BASAL.ARTC_ARTC_ID = PROMOS_2.ARTC_ARTC_ID\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "ace = cursor.fetch_pandas_all()\n",
    "ace.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 7 - Aceleracion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ace['DIFF'] = ace['VNTA_UNIDADES'] - ace['VENTA_BASAL']\n",
    "\n",
    "ace['UNIDADES_DIV_BASAL'] = round(ace['VNTA_UNIDADES'] / ace['VENTA_BASAL'], 1)\n",
    "for i in ['DIFF', 'VNTA_UNIDADES', 'VENTA_BASAL']:\n",
    "    ace[i] = ace[i].astype(int)\n",
    "ace.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 8 - Aceleracion por Subclase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ace_2 = ace.groupby(['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['VNTA_UNIDADES', 'VENTA_BASAL'].sum().reset_index()\n",
    "\n",
    "ace_2['DIFF'] = ace_2['VNTA_UNIDADES'] - ace_2['VENTA_BASAL']\n",
    "ace_2['UNIDADES_DIV_BASAL'] = round(ace_2['VNTA_UNIDADES'] / ace_2['VENTA_BASAL'], 1)\n",
    "ace_2.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 9 - Aceleracion Resumen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ace_3 = pd.DataFrame(ace[['VNTA_UNIDADES', 'VENTA_BASAL']].sum(axis=0)).T\n",
    "ace_3['DIFF'] = ace_3['VNTA_UNIDADES'] - ace_3['VENTA_BASAL']\n",
    "ace_3['UNIDADES_DIV_BASAL'] = round(ace_3['VNTA_UNIDADES'] / ace_3['VENTA_BASAL'], 1)\n",
    "ace_3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tasa de Cierre"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Promos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH PROMOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        LPE.EVENTO_DESC,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        CLA.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_DESC\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    FV.TIEM_DIA_ID,\n",
    "    IM.CLASE,\n",
    "    CLA.CLASS_NAME,\n",
    "    IM.SUBCLASE,\n",
    "    SUB.SUB_NAME,\n",
    "    LAA.ORIN,\n",
    "    LGL.GEOG_LOCL_COD,\n",
    "    COUNT(DISTINCT FV.TICKET) AS TICKETS\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_VENTAS AS FV\n",
    "    INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON FV.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FV .ARTC_ARTC_ID\n",
    "    INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "    INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "    INNER JOIN PROMOS ON PROMOS.ORIN = LAA.ORIN AND PROMOS.GEOG_LOCL_COD = LGL.GEOG_LOCL_COD AND FV.TIEM_DIA_ID BETWEEN PROMOS.INICIO AND PROMOS.FIN\n",
    "WHERE\n",
    "    TO_VARCHAR(FV.TIEM_DIA_ID, 'YYYY-MM') = '{periodo_query}'\n",
    "GROUP BY\n",
    "    ALL\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "tick_1 = cursor.fetch_pandas_all()\n",
    "print(tick_1.shape[0])\n",
    "tick_1.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tick_2 = tick_1.groupby(['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['TICKETS'].sum().reset_index()\n",
    "tick_2.rename({'TICKETS':'TICKETS_PROMO'}, axis = 1, inplace = True)\n",
    "tick_2.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Para toda la subclase en dicho local"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH PROMOS AS\n",
    "    (\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        LPE.EVENTO_DESC,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        CLA.CLASE,\n",
    "        CLA.CLASS_NAME,\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        FP.GEOG_LOCL_ID,\n",
    "        LGL.GEOG_LOCL_COD,\n",
    "        LGL.GEOG_LOCL_DESC\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FP.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON LGL.GEOG_LOCL_ID = FP.GEOG_LOCL_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '{periodo_query}' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '{periodo_query}')\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    FV.TIEM_DIA_ID,\n",
    "    IM.CLASE,\n",
    "    CLA.CLASS_NAME,\n",
    "    IM.SUBCLASE,\n",
    "    SUB.SUB_NAME,\n",
    "    LAA.ORIN,\n",
    "    LGL.GEOG_LOCL_COD,\n",
    "    COUNT(DISTINCT FV.TICKET) AS TICKETS\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_VENTAS AS FV\n",
    "    INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON FV.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "    INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON LAA.ARTC_ARTC_ID = FV .ARTC_ARTC_ID\n",
    "    INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "    INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    INNER JOIN MSTRDB.DWH.CLASS AS CLA ON CLA.CLASE = IM.CLASE\n",
    "    INNER JOIN PROMOS ON PROMOS.SUBCLASE = IM.SUBCLASE AND PROMOS.GEOG_LOCL_COD = LGL.GEOG_LOCL_COD AND FV.TIEM_DIA_ID BETWEEN PROMOS.INICIO AND PROMOS.FIN\n",
    "WHERE\n",
    "    TO_VARCHAR(FV.TIEM_DIA_ID, 'YYYY-MM') = '{periodo_query}'\n",
    "GROUP BY\n",
    "    ALL\n",
    "'''\n",
    "\n",
    "cursor.execute(query.format(periodo_query = periodo))\n",
    "tick_total_1 = cursor.fetch_pandas_all()\n",
    "print(tick_total_1.shape[0])\n",
    "tick_total_1.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tick_total_2 = tick_total_1.groupby(['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'])['TICKETS'].sum().reset_index()\n",
    "tick_total_2.rename({'TICKETS':'TICKETS_TOTALES'}, axis = 1, inplace = True)\n",
    "tick_total_2.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 10 - Tasa de Cierre"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_5 = tick_total_2.merge(tick_2, on = ['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME'], how = 'left')\n",
    "for i in ['TICKETS_TOTALES', 'TICKETS_PROMO']:\n",
    "    e_5[i].fillna(0, inplace = True)\n",
    "    e_5[i] = e_5[i].astype(int)\n",
    "e_5['RATIO_TICKETS'] = round((e_5['TICKETS_PROMO'] / e_5['TICKETS_TOTALES']) * 100, 1)\n",
    "e_5 =e_5[['CLASE', 'CLASS_NAME', 'SUBCLASE', 'SUB_NAME', 'TICKETS_PROMO', 'TICKETS_TOTALES', 'RATIO_TICKETS']]\n",
    "e_5.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MAURI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Promos Distintas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 11 - Numero de Eventos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT\n",
    "        LPTO.*,\n",
    "        COUNT(DISTINCT LPE.EVENTO_ID) AS NUMERO_EVENTOS\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "        AND (TO_VARCHAR(FP.PROM_FECHA_INICIO, 'YYYY-MM') = '2023-01' OR TO_VARCHAR(FP.PROM_FECHA_FIN, 'YYYY-MM') = '2023-01')\n",
    "    GROUP BY\n",
    "        ALL\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "eventos = cursor.fetch_pandas_all()\n",
    "eventos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Precios Oferta"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 12 - Precios Oferta"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   EVENTO_ID       DESDE       HASTA               OFERTA\n0        NaN  2024-01-04  2024-01-10    OFERTATA ENERO 01\n1        NaN  2024-01-11  2024-01-17    OFERTATA ENERO 02\n2        NaN  2024-02-15  2024-02-21  OFERTATA FEBRERO 07\n3        NaN  2024-02-22  2024-02-28  OFERTATA FEBRERO 08",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EVENTO_ID</th>\n      <th>DESDE</th>\n      <th>HASTA</th>\n      <th>OFERTA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>2024-01-04</td>\n      <td>2024-01-10</td>\n      <td>OFERTATA ENERO 01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>2024-01-11</td>\n      <td>2024-01-17</td>\n      <td>OFERTATA ENERO 02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>2024-02-15</td>\n      <td>2024-02-21</td>\n      <td>OFERTATA FEBRERO 07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>2024-02-22</td>\n      <td>2024-02-28</td>\n      <td>OFERTATA FEBRERO 08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_fechas = 'https://docs.google.com/spreadsheets/d/1JnayuiljvaOebik4gKqNgxSLD6RO2AS8euG7apQykW8/export?format=csv'\n",
    "fechas = pd.read_csv(url_fechas)\n",
    "fechas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   TIPO_OFERTA_ID TIPO_OFERTA_DESC      INICIO         FIN PRECIO DESDE  \\\n0              12   Otros Mailings  2023-12-26  2024-01-03   2024-01-04   \n1              12   Otros Mailings  2023-12-26  2024-01-03   2024-01-04   \n\n  PRECIO HASTA        ORIN  PROM_PVP_OFERTA  \n0   2024-01-10  1000052069             40.0  \n1   2024-01-10  1000149602            135.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIPO_OFERTA_ID</th>\n      <th>TIPO_OFERTA_DESC</th>\n      <th>INICIO</th>\n      <th>FIN</th>\n      <th>PRECIO DESDE</th>\n      <th>PRECIO HASTA</th>\n      <th>ORIN</th>\n      <th>PROM_PVP_OFERTA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12</td>\n      <td>Otros Mailings</td>\n      <td>2023-12-26</td>\n      <td>2024-01-03</td>\n      <td>2024-01-04</td>\n      <td>2024-01-10</td>\n      <td>1000052069</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12</td>\n      <td>Otros Mailings</td>\n      <td>2023-12-26</td>\n      <td>2024-01-03</td>\n      <td>2024-01-04</td>\n      <td>2024-01-10</td>\n      <td>1000149602</td>\n      <td>135.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "        LPTO.*,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        --LAA.ARTC_ARTC_ID,\n",
    "        --LAA.ARTC_ARTC_COD,\n",
    "        LAA.ORIN,\n",
    "        --LAA.ARTC_ARTC_DESC,\n",
    "        FP.PROM_PVP_OFERTA\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON FP.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID in (10,11,12)\n",
    "        AND FP.PROM_FECHA_INICIO >= DATEADD(DAY, -30, '{desde_snow}')\n",
    "        AND FP.PROM_FECHA_FIN < '{desde_snow}'\n",
    "'''\n",
    "\n",
    "df_precios_oferta = pd.DataFrame()\n",
    "for i in range(len(fechas)):\n",
    "    desde = fechas.iloc[i]['DESDE']\n",
    "    hasta = fechas.iloc[i]['HASTA']\n",
    "\n",
    "    cursor.execute(query.format(desde_snow = desde, hasta_snow = hasta))\n",
    "    df_aux = cursor.fetch_pandas_all()\n",
    "    df_aux['PRECIO DESDE'] = desde\n",
    "    df_aux['PRECIO HASTA'] = hasta\n",
    "    df_precios_oferta = pd.concat([df_precios_oferta, df_aux])\n",
    "df_precios_oferta = df_precios_oferta[['TIPO_OFERTA_ID', 'TIPO_OFERTA_DESC', 'INICIO', 'FIN', 'PRECIO DESDE', 'PRECIO HASTA', 'ORIN', 'PROM_PVP_OFERTA']]\n",
    "df_precios_oferta.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ARTC_ARTC_ID'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m df_precios_oferta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFIN\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(df_precios_oferta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFIN\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Create a new 'Rank' column based on the maximum date for each element of 'X'\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m df_precios_oferta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mR\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf_precios_oferta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mARTC_ARTC_ID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFIN\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mrank(ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_precios_oferta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mARTC_ARTC_ID\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mnunique())\n\u001B[0;32m      7\u001B[0m df_precios_oferta \u001B[38;5;241m=\u001B[39m df_precios_oferta[df_precios_oferta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mR\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Tareas\\Analisis\\!Python\\env\\lib\\site-packages\\pandas\\core\\frame.py:7631\u001B[0m, in \u001B[0;36mDataFrame.groupby\u001B[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001B[0m\n\u001B[0;32m   7627\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_axis_number(axis)\n\u001B[0;32m   7629\u001B[0m \u001B[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001B[39;00m\n\u001B[0;32m   7630\u001B[0m \u001B[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001B[39;00m\n\u001B[1;32m-> 7631\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameGroupBy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   7632\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7633\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7634\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7635\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7636\u001B[0m \u001B[43m    \u001B[49m\u001B[43mas_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7637\u001B[0m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7638\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroup_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7639\u001B[0m \u001B[43m    \u001B[49m\u001B[43msqueeze\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   7640\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobserved\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobserved\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7641\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdropna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdropna\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   7642\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Tareas\\Analisis\\!Python\\env\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:889\u001B[0m, in \u001B[0;36mGroupBy.__init__\u001B[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001B[0m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m grouper \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgroupby\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgrouper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_grouper\n\u001B[1;32m--> 889\u001B[0m     grouper, exclusions, obj \u001B[38;5;241m=\u001B[39m \u001B[43mget_grouper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    895\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobserved\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobserved\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmutated\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmutated\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdropna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropna\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    898\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj \u001B[38;5;241m=\u001B[39m obj\n\u001B[0;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m_get_axis_number(axis)\n",
      "File \u001B[1;32m~\\Desktop\\Tareas\\Analisis\\!Python\\env\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:862\u001B[0m, in \u001B[0;36mget_grouper\u001B[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001B[0m\n\u001B[0;32m    860\u001B[0m         in_axis, level, gpr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, gpr, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 862\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(gpr)\n\u001B[0;32m    863\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(gpr, Grouper) \u001B[38;5;129;01mand\u001B[39;00m gpr\u001B[38;5;241m.\u001B[39mkey \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m     \u001B[38;5;66;03m# Add key to exclusions\u001B[39;00m\n\u001B[0;32m    865\u001B[0m     exclusions\u001B[38;5;241m.\u001B[39madd(gpr\u001B[38;5;241m.\u001B[39mkey)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'ARTC_ARTC_ID'"
     ]
    }
   ],
   "source": [
    "df_precios_oferta['FIN'] = pd.to_datetime(df_precios_oferta['FIN'])\n",
    "\n",
    "# Create a new 'Rank' column based on the maximum date for each element of 'X'\n",
    "df_precios_oferta['R'] = df_precios_oferta.groupby('ARTC_ARTC_ID')['FIN'].rank(ascending=False, method='max').astype(int)\n",
    "print(df_precios_oferta['ARTC_ARTC_ID'].nunique())\n",
    "\n",
    "df_precios_oferta = df_precios_oferta[df_precios_oferta['R'] == 1]\n",
    "print(df_precios_oferta['ARTC_ARTC_ID'].nunique())\n",
    "df_precios_oferta.drop_duplicates(subset = 'ARTC_ARTC_ID', keep = 'first', inplace = True)\n",
    "df_precios_oferta.drop(['R'], axis = 1, inplace = True)\n",
    "print(df_precios_oferta.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_precios_oferta[df_precios_oferta.duplicated(subset = 'ARTC_ARTC_ID', keep = False)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BASE_OPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 13 - OPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT\n",
    "        LAA.ARTC_ARTC_ID,\n",
    "        LAA.ARTC_ARTC_COD,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        --LAA.ORIN,\n",
    "        ROUND(AVG(OPT.PRECIO_COMPETENCIA), 1) AS AVG_PRECIO_COMPETENCIA\n",
    "    FROM\n",
    "        SPIKE.SPIKE.BASE_OPT AS OPT\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON OPT.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_GEOG_LOCAL AS LGL ON OPT.GEOG_LOCL_ID = LGL.GEOG_LOCL_ID\n",
    "    GROUP BY\n",
    "        ALL\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "opt = cursor.fetch_pandas_all()\n",
    "opt.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Locales Activos Ayer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 14 - Locales Activos Ayer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "         ORIN  LOCALES_ACTIVOS_AYER\n0  1000014196                     1\n1  1000050646                    83",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ORIN</th>\n      <th>LOCALES_ACTIVOS_AYER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000014196</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000050646</td>\n      <td>83</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    --LAA.ARTC_ARTC_DESC AS ARTICULO,\n",
    "    LAA.ORIN,\n",
    "    --LAA.ARTC_ARTC_ID,\n",
    "    COUNT(DISTINCT FS.GEOG_LOCL_ID) AS LOCALES_ACTIVOS_AYER\n",
    "FROM\n",
    "    MSTRDB.DWH.FT_STOCK AS FS\n",
    "    LEFT JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON FS.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID\n",
    "WHERE\n",
    "    ARTC_ESTA_ID = 4\n",
    "    AND GEOG_LOCL_ID IN (SELECT GEOG_LOCL_ID FROM MSTRDB.DWH.LU_GEOG_LOCAL WHERE GEOG_UNNG_ID = 2)\n",
    "    AND GEOG_LOCL_ID IN (SELECT GEOG_LOCL_ID FROM MSTRDB.DWH.LU_GEOG_LOCAL WHERE GEOG_LOCL_COD NOT IN (198, 100))\n",
    "    AND FS.TIEM_DIA_ID = CURRENT_DATE() - 1\n",
    "GROUP BY\n",
    "    ALL\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "e_7 = cursor.fetch_pandas_all()\n",
    "e_7.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1, 83, 89, 91, 70, 75, 93, 92, 71, 58, 94, 90, 69, 22, 67, 33, 50,\n       51, 60, 61, 72,  5, 49, 85, 86, 62, 38, 65, 74, 48, 68, 35, 87, 52,\n       81, 30, 79, 44, 47, 77, 29, 37, 40, 63, 73, 43, 80, 57, 88, 27, 26,\n       39, 64, 66, 15, 55, 42, 82, 34, 53, 78, 59, 28, 10, 31, 21, 36, 54,\n       45, 41, 84, 20, 76, 46, 19, 32,  2,  8, 25, 24, 23, 18, 56,  9, 12,\n       95,  4,  3, 17, 14,  7, 11, 13, 16,  6], dtype=int64)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_7['LOCALES_ACTIVOS_AYER'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Days on Hand"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 15 - days on hand ARTICULO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     SUBCLASE                                  ARTC_ARTC_DESC        ORIN  \\\n0  1500050002          CAVIAR NEGRO STUK DEUSTECHER 50.00 U 1  1000054044   \n1  1600040003  COPOS DE MAIZ NATURALES MULTIAHORRO 200.00 G 1  1000054303   \n\n   ARTC_ARTC_ID  UNIDADES  UNIDADES_VENDIDAS  \n0         69378       0.0                0.0  \n1         69450       0.0                0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SUBCLASE</th>\n      <th>ARTC_ARTC_DESC</th>\n      <th>ORIN</th>\n      <th>ARTC_ARTC_ID</th>\n      <th>UNIDADES</th>\n      <th>UNIDADES_VENDIDAS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1500050002</td>\n      <td>CAVIAR NEGRO STUK DEUSTECHER 50.00 U 1</td>\n      <td>1000054044</td>\n      <td>69378</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600040003</td>\n      <td>COPOS DE MAIZ NATURALES MULTIAHORRO 200.00 G 1</td>\n      <td>1000054303</td>\n      <td>69450</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "WITH STOCK AS\n",
    "    (\n",
    "    SELECT\n",
    "        IM.SUBCLASE,\n",
    "        LAA.ARTC_ARTC_DESC,\n",
    "        LAA.ORIN,\n",
    "        LAA.ARTC_ARTC_ID,\n",
    "        SUM(FS.STCK_UNIDADES) AS UNIDADES\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_STOCK AS FS\n",
    "        LEFT JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON FS.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON LAA.ORIN = IM.ITEM\n",
    "    WHERE\n",
    "        FS.TIEM_DIA_ID = CURRENT_DATE() - 1\n",
    "    GROUP BY\n",
    "        ALL\n",
    "    ),\n",
    "\n",
    "VENTAS AS\n",
    "    (\n",
    "    SELECT\n",
    "        FV.ARTC_ARTC_ID,\n",
    "        (SUM(FV.VNTA_UNIDADES) / 30) AS UNIDADES_VENDIDAS\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_VENTAS AS FV\n",
    "    WHERE\n",
    "        FV.TIEM_DIA_ID >= DATEADD(MONTH, -1, CURRENT_DATE()-1)\n",
    "    GROUP BY\n",
    "        ALL\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    STOCK.*,\n",
    "    COALESCE(VENTAS.UNIDADES_VENDIDAS, 0) AS UNIDADES_VENDIDAS\n",
    "FROM\n",
    "    STOCK\n",
    "    LEFT JOIN VENTAS ON VENTAS.ARTC_ARTC_ID = STOCK.ARTC_ARTC_ID\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "e_8 = cursor.fetch_pandas_all()\n",
    "e_8 = e_8[e_8['UNIDADES'] != 0]\n",
    "e_8['DAYS ON HAND'] = e_8['UNIDADES'] / e_8['UNIDADES_VENDIDAS']\n",
    "e_8['DAYS ON HAND'][(e_8['UNIDADES'] == 0) & (e_8['UNIDADES_VENDIDAS'] == 0)] = 0\n",
    "e_8['DAYS ON HAND'] = round(e_8['DAYS ON HAND'], 2)\n",
    "e_8['UNIDADES'] = round(e_8['UNIDADES'], 2)\n",
    "e_8['UNIDADES_VENDIDAS'] = round(e_8['UNIDADES_VENDIDAS'], 2)\n",
    "e_8 = e_8[['SUBCLASE', 'ORIN', 'DAYS ON HAND']]\n",
    "e_8.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 16 - days on hand SUBCLASE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "     SUBCLASE                     SUB_NAME  UNIDADES  UNIDADES_VENDIDAS  \\\n0  8900010008            PANOS ABSORVENTES   34238.0             533.47   \n1  6900010001  ARMA DE DARDOS O MUNICIONES    1278.0              10.60   \n\n   DAYS ON HAND  \n0         64.18  \n1        120.57  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SUBCLASE</th>\n      <th>SUB_NAME</th>\n      <th>UNIDADES</th>\n      <th>UNIDADES_VENDIDAS</th>\n      <th>DAYS ON HAND</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8900010008</td>\n      <td>PANOS ABSORVENTES</td>\n      <td>34238.0</td>\n      <td>533.47</td>\n      <td>64.18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6900010001</td>\n      <td>ARMA DE DARDOS O MUNICIONES</td>\n      <td>1278.0</td>\n      <td>10.60</td>\n      <td>120.57</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "WITH STOCK AS\n",
    "    (\n",
    "    SELECT\n",
    "        SUB.SUBCLASE,\n",
    "        SUB.SUB_NAME,\n",
    "        SUM(FS.STCK_UNIDADES) AS UNIDADES\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_STOCK AS FS\n",
    "        LEFT JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON FS.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        FS.TIEM_DIA_ID = CURRENT_DATE() - 1\n",
    "    GROUP BY\n",
    "        ALL\n",
    "    ),\n",
    "\n",
    "VENTAS AS\n",
    "    (\n",
    "    SELECT\n",
    "        SUB.SUBCLASE,\n",
    "        (SUM(FV.VNTA_UNIDADES) / 30) AS UNIDADES_VENDIDAS\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_VENTAS AS FV\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON FV.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.ITEM_MASTER AS IM ON IM.ITEM = LAA.ORIN\n",
    "        INNER JOIN MSTRDB.DWH.SUBCLASS AS SUB ON SUB.SUBCLASE = IM.SUBCLASE\n",
    "    WHERE\n",
    "        FV.TIEM_DIA_ID >= DATEADD(MONTH, -1, CURRENT_DATE()-1)\n",
    "    GROUP BY\n",
    "        ALL\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    STOCK.*,\n",
    "    COALESCE(VENTAS.UNIDADES_VENDIDAS, 0) AS UNIDADES_VENDIDAS\n",
    "FROM\n",
    "    STOCK\n",
    "    LEFT JOIN VENTAS ON VENTAS.SUBCLASE = STOCK.SUBCLASE\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "e_9 = cursor.fetch_pandas_all()\n",
    "e_9 = e_9[e_9['UNIDADES'] != 0]\n",
    "e_9['DAYS ON HAND'] = e_9['UNIDADES'] / e_9['UNIDADES_VENDIDAS']\n",
    "e_9['DAYS ON HAND'][(e_9['UNIDADES'] == 0) & (e_9['UNIDADES_VENDIDAS'] == 0)] = 0\n",
    "e_9['DAYS ON HAND'] = round(e_9['DAYS ON HAND'], 2)\n",
    "e_9['UNIDADES'] = round(e_9['UNIDADES'], 2)\n",
    "e_9['UNIDADES_VENDIDAS'] = round(e_9['UNIDADES_VENDIDAS'], 2)\n",
    "e_9 = e_9[['SUBCLASE', 'ORIN', 'DAYS ON HAND']]\n",
    "e_9.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [SUBCLASE, ARTC_ARTC_DESC, ORIN, ARTC_ARTC_ID, UNIDADES, UNIDADES_VENDIDAS, DAYS ON HAND]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SUBCLASE</th>\n      <th>ARTC_ARTC_DESC</th>\n      <th>ORIN</th>\n      <th>ARTC_ARTC_ID</th>\n      <th>UNIDADES</th>\n      <th>UNIDADES_VENDIDAS</th>\n      <th>DAYS ON HAND</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_9['DAYS ON HAND'][e_9['DAYS ON HAND'] == np.inf] = 99999999\n",
    "e_9[e_9['DAYS ON HAND'] == np.inf]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Precios Stock Mediano ayer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tabla 17 - Precios Stock Mediano ayer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "        LPTO.*,\n",
    "        FP.PROM_FECHA_INICIO AS INICIO,\n",
    "        FP.PROM_FECHA_FIN AS FIN,\n",
    "        --LAA.ARTC_ARTC_ID,\n",
    "        --LAA.ARTC_ARTC_COD,\n",
    "        --LAA.ARTC_ARTC_DESC,\n",
    "        LAA.ORIN,\n",
    "        MEDIAN(FS.STCK_PRECIO_VENTA_DIA_CIVA) AS PRECIO_STOCK_MEDIANO\n",
    "    FROM\n",
    "        MSTRDB.DWH.FT_PROMOS AS FP\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_EVENTO AS LPE ON LPE.EVENTO_ID = FP.EVENTO_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_PROM_TIPO_OFERTA AS LPTO ON LPTO.TIPO_OFERTA_ID = LPE.TIPO_OFERTA_ID\n",
    "        INNER JOIN MSTRDB.DWH.LU_ARTC_ARTICULO AS LAA ON FP.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID\n",
    "        INNER JOIN MSTRDB.DWH.FT_STOCK AS FS ON FS.ARTC_ARTC_ID = LAA.ARTC_ARTC_ID AND FS.TIEM_DIA_ID = CURRENT_DATE - 1\n",
    "    WHERE\n",
    "        LPTO.TIPO_OFERTA_ID IN (10, 11, 12)\n",
    "    GROUP BY\n",
    "        ALL\n",
    "'''\n",
    "\n",
    "cursor.execute(query)\n",
    "df_precios_stock_mediano = cursor.fetch_pandas_all()\n",
    "df_precios_stock_mediano.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mauri\n",
    "\n",
    "with pd.ExcelWriter(\n",
    "        f\"C:\\\\Users\\\\leonardo.mangold\\\\PycharmProjects\\\\analisis\\\\kpis_promos_mauri\\\\Entregas\\\\Promos {datetime.today().strftime('%Y-%m-%d')}.xlsx\",\n",
    "        engine='xlsxwriter') as writer:\n",
    "\n",
    "\n",
    "\n",
    "    precios.to_excel(writer, sheet_name=f\"Precios Oferta {datetime.today().strftime('%Y-%m-%d')}\", index=False)  # tabla 12\n",
    "    df_precios_stock_mediano.to_excel(writer, sheet_name=f\"Precios Stock Mediano Ayer\", index=False)  # tabla 17\n",
    "    opt.to_excel(writer, sheet_name=f\"OPT - Media Precios Compet\", index=False)  # tabla 13\n",
    "    e_7.to_excel(writer, sheet_name=f\"Numero de Locales Activos Ayer\", index=False)  # tabla 14\n",
    "    e_8.to_excel(writer, sheet_name=f\"Days on Hand - Articulos\", index=False)  # tabla 15\n",
    "    e_9.to_excel(writer, sheet_name=f\"Days on Hand - Subclases\", index=False)  # tabla 16\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sys.exit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f\"C:\\\\Users\\\\leonardo.mangold\\\\PycharmProjects\\\\analisis\\\\kpis_promos_mauri\\\\Entregas\\\\Promos {datetime.today().strftime('%Y-%m-%d')}.xlsx\", engine='xlsxwriter') as writer:\n",
    "    e_1.to_excel(writer, sheet_name='Articulos Publicados', index=False) # tabla 1\n",
    "    arts_2.to_excel(writer, sheet_name='Venta y GB1 por Promo', index=False) # tabla 2\n",
    "    e_6.to_excel(writer, sheet_name='Numero de Subclases', index=False) # tabla 3\n",
    "    e_2.to_excel(writer, sheet_name='Venta y GB1 por Subclase', index=False) # tabla 4\n",
    "    e_3.to_excel(writer, sheet_name='Venta y GB1 Promo Agrupado', index=False) # tabla 5\n",
    "    e_4.to_excel(writer, sheet_name='Num Articulos por Subclase', index=False) # tabla 6\n",
    "    ace.to_excel(writer, sheet_name='Aceleracion', index=False) # tabla 7\n",
    "    ace_2.to_excel(writer, sheet_name='Aceleracion por Subclase', index=False) # tabla 8\n",
    "    ace_3.to_excel(writer, sheet_name='Aceleracion Resumen', index=False) # tabla 9\n",
    "    e_5.to_excel(writer, sheet_name='Tickets', index=False) # tabla 10\n",
    "    eventos.to_excel(writer, sheet_name='Numero de Eventos', index=False) # tabla 11\n",
    "    df_precios_oferta.to_excel(writer, sheet_name=f\"Precios {datetime.today().strftime('%Y-%m-%d')}\", index=False) # tabla 12\n",
    "    opt.to_excel(writer, sheet_name=f\"OPT - Media Precios Compet\", index=False) # tabla 13\n",
    "    e_7.to_excel(writer, sheet_name=f\"Numero de Locales Activos Ayer\", index=False) # tabla 14\n",
    "    e_8.to_excel(writer, sheet_name=f\"Days on Hand - Articulos\", index=False) # tabla 15\n",
    "    e_9.to_excel(writer, sheet_name=f\"Days on Hand - Subclases\", index=False) # tabla 16\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'2023-12-13'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today().strftime('%Y-%m-%d')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fin"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c19c5efd8f4b93ccbd4006c6f9f93fa19f57b77bfb4a2e5dfb55a2b8dd9ae6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
